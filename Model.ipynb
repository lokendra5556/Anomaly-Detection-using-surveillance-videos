{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r1r6AvU6vj1J"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "id": "cpBFMchEvCff"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dGa5WAGDvCfp"
   },
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_vPpZaDavCfq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from time import time\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wo7c_ojMvCfq"
   },
   "source": [
    "# Build Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zEjb3IP5vCfr"
   },
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "from keras.utils import np_utils\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    \"\"\"Data Generator inherited from keras.utils.Sequence\n",
    "    Args: \n",
    "        directory: the path of data set, and each sub-folder will be assigned to one class\n",
    "        batch_size: the number of data points in each batch\n",
    "        shuffle: whether to shuffle the data per epoch\n",
    "    Note:\n",
    "        If you want to load file with other data format, please fix the method of \"load_data\" as you want\n",
    "    \"\"\"\n",
    "    def __init__(self, directory, split_name = \"training\", train_split = 1, seed = 2, batch_size=1,optical_flow = True, shuffle=True, data_augmentation=True):\n",
    "      # Initialize the params\n",
    "        self.batch_size = batch_size\n",
    "        self.split_name = split_name\n",
    "        self.train_split = train_split\n",
    "        self.seed = seed\n",
    "        self.directory = directory\n",
    "        self.shuffle = shuffle\n",
    "        self.optical_flow = optical_flow\n",
    "        self.data_aug = data_augmentation\n",
    "        # Load all the save_path of files, and create a dictionary that save the pair of \"data:label\"\n",
    "        self.X_path, self.Y_dict = self.search_data(split_name, train_split, seed) \n",
    "        # Print basic statistics information\n",
    "        self.print_stats()\n",
    "        return None\n",
    "\n",
    "        \n",
    "        \n",
    "    def search_data(self,split_name, train_split, seed):\n",
    "        X_path = []\n",
    "        Y_dict = {}\n",
    "        # list all kinds of sub-folders\n",
    "        self.dirs = sorted(os.listdir(self.directory))\n",
    "        one_hots = np_utils.to_categorical(range(len(self.dirs)))\n",
    "        for i,folder in enumerate(self.dirs):\n",
    "            folder_path = os.path.join(self.directory,folder)\n",
    "                     \n",
    "            np.random.seed(seed)\n",
    "            files = os.listdir(folder_path)\n",
    "            np.random.shuffle(files)\n",
    "            lp = int(len(files)*train_split)\n",
    "                   \n",
    "            if split_name == \"training\":\n",
    "                for j in range(0,lp):\n",
    "                    file_path = os.path.join(folder_path,files[j])\n",
    "                    # append the each file path, and keep its label  \n",
    "                    X_path.append(file_path)\n",
    "                    Y_dict[file_path] = one_hots[i]\n",
    "            elif split_name == \"validation\":\n",
    "                for j in range(lp,len(files)):\n",
    "                    file_path = os.path.join(folder_path,files[j])\n",
    "                    # append the each file path, and keep its label  \n",
    "                    X_path.append(file_path)\n",
    "                    Y_dict[file_path] = one_hots[i]\n",
    "            \n",
    "        return X_path, Y_dict\n",
    "    \n",
    "    \n",
    "    def add_optical_flow(self, video):\n",
    "       \n",
    "        # initialize the list of optical flows\n",
    "        gray_video = []\n",
    "        for i in range(len(video)):\n",
    "            img = cv2.cvtColor(video[i], cv2.COLOR_RGB2GRAY)\n",
    "            gray_video.append(np.reshape(img,(224,224,1)))\n",
    "\n",
    "        flows = []\n",
    "        for i in range(0,len(video)-1):\n",
    "            # calculate optical flow between each pair of frames\n",
    "            flow = cv2.calcOpticalFlowFarneback(gray_video[i], gray_video[i+1], None, 0.5, 3, 15, 3, 5, 1.2, cv2.OPTFLOW_FARNEBACK_GAUSSIAN)\n",
    "            # subtract the mean in order to eliminate the movement of camera\n",
    "            flow[..., 0] -= np.mean(flow[..., 0])\n",
    "            flow[..., 1] -= np.mean(flow[..., 1])\n",
    "            # normalize each component in optical flow\n",
    "            flow[..., 0] = cv2.normalize(flow[..., 0],None,0,255,cv2.NORM_MINMAX)\n",
    "            flow[..., 1] = cv2.normalize(flow[..., 1],None,0,255,cv2.NORM_MINMAX)\n",
    "            # Add into list \n",
    "            flows.append(flow)\n",
    "        \n",
    "        # Padding the last frame as empty array\n",
    "        flows.append(np.zeros((224,224,2)))\n",
    "\n",
    "        result = np.zeros((len(flows),224,224,5))\n",
    "        result[...,:3] = video\n",
    "        result[...,3:] = flows\n",
    "        return np.array(result, dtype=np.float32)\n",
    "\n",
    "    \n",
    "    def print_stats(self):\n",
    "        # calculate basic information\n",
    "        self.n_files = len(self.X_path)\n",
    "        self.n_classes = len(self.dirs)\n",
    "        self.indexes = np.arange(len(self.X_path))\n",
    "        np.random.shuffle(self.indexes)\n",
    "        # Output states\n",
    "        print(\"Found {} files belonging to {} classes.\".format(self.n_files,self.n_classes))\n",
    "        for i,label in enumerate(self.dirs):\n",
    "            print('%10s : '%(label),i)\n",
    "        return None\n",
    "    \n",
    "    def __len__(self):\n",
    "        # calculate the iterations of each epoch\n",
    "        steps_per_epoch = np.ceil(len(self.X_path) / float(self.batch_size))\n",
    "        return int(steps_per_epoch)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get the data of each batch\n",
    "        \"\"\"\n",
    "        # get the indexs of each batch\n",
    "        batch_indexs = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # using batch_indexs to get path of current batch\n",
    "        batch_path = [self.X_path[k] for k in batch_indexs]\n",
    "        # get batch data\n",
    "        batch_x, batch_y = self.data_generation(batch_path)\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # shuffle the data at each end of epoch\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def data_generation(self, batch_path):\n",
    "        # load data into memory, you can change the np.load to any method you want\n",
    "        batch_x = [self.load_data(x) for x in batch_path]\n",
    "        batch_y = [self.Y_dict[x] for x in batch_path]\n",
    "        # transfer the data format and take one-hot coding for labels\n",
    "        batch_x = np.array(batch_x)\n",
    "        batch_y = np.array(batch_y)\n",
    "        return batch_x, batch_y\n",
    "      \n",
    "    def normalize(self, data):\n",
    "        mean = np.mean(data)\n",
    "        std = np.std(data)\n",
    "        return (data-mean) / std\n",
    "    \n",
    "    def random_flip(self, video, prob):\n",
    "        s = np.random.rand()\n",
    "        if s < prob:\n",
    "            video = np.flip(m=video, axis=2)\n",
    "        return video    \n",
    "    \n",
    "\n",
    "    def color_jitter(self,video):\n",
    "        # range of s-component: 0-1\n",
    "        # range of v component: 0-255\n",
    "        s_jitter = np.random.uniform(-0.2,0.2)\n",
    "        v_jitter = np.random.uniform(-30,30)\n",
    "        for i in range(len(video)):\n",
    "            hsv = cv2.cvtColor(video[i], cv2.COLOR_RGB2HSV)\n",
    "            s = hsv[...,1] + s_jitter\n",
    "            v = hsv[...,2] + v_jitter\n",
    "            s[s<0] = 0\n",
    "            s[s>1] = 1\n",
    "            v[v<0] = 0\n",
    "            v[v>255] = 255\n",
    "            hsv[...,1] = s\n",
    "            hsv[...,2] = v\n",
    "            video[i] = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "        return video\n",
    "        \n",
    "    def load_data(self, path):\n",
    "        # load the processed .npy files which have 5 channels (1-3 for RGB, 4-5 for optical flows)\n",
    "        \n",
    "        data=[]\n",
    "        cap=cv2.VideoCapture(path)\n",
    "        length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        for i in range(length):\n",
    "            res,frame=cap.read()\n",
    "            frame=cv2.resize(frame,(224,224))\n",
    "            data.append(frame)\n",
    "\n",
    "        data = np.float32(data)\n",
    "        \n",
    "\n",
    "        if self.optical_flow:\n",
    "                data = self.add_optical_flow(data)\n",
    "                \n",
    "        # whether to utilize the data augmentation\n",
    "        if  self.data_aug:\n",
    "            data[...,:3] = self.color_jitter(data[...,:3])\n",
    "            data = self.random_flip(data, prob=0.5)\n",
    "        # normalize rgb images and optical flows, respectively\n",
    "        data[...,:3] = self.normalize(data[...,:3])\n",
    "        data[...,3:] = self.normalize(data[...,3:])\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTEnrnDovCfx"
   },
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2180,
     "status": "ok",
     "timestamp": 1612593976342,
     "user": {
      "displayName": "# code_to_one",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgZU-qSLvdj-I2F3Q_fKV-Sp76UZhosfWOoHTCY=s64",
      "userId": "17190782398639435811"
     },
     "user_tz": -330
    },
    "id": "iiH80-LfvCf0"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization, Activation, LeakyReLU, Add, Multiply\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.core import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 952,
     "status": "ok",
     "timestamp": 1612593978193,
     "user": {
      "displayName": "# code_to_one",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgZU-qSLvdj-I2F3Q_fKV-Sp76UZhosfWOoHTCY=s64",
      "userId": "17190782398639435811"
     },
     "user_tz": -330
    },
    "id": "Iwi1HqLYvCf0"
   },
   "outputs": [],
   "source": [
    "# extract the rgb images \n",
    "def get_rgb(input_x):\n",
    "    rgb = input_x[...,:3]\n",
    "    return rgb\n",
    "\n",
    "# extract the optical flows\n",
    "def get_opt(input_x):\n",
    "    opt= input_x[...,3:5]\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7172,
     "status": "ok",
     "timestamp": 1612593986684,
     "user": {
      "displayName": "# code_to_one",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgZU-qSLvdj-I2F3Q_fKV-Sp76UZhosfWOoHTCY=s64",
      "userId": "17190782398639435811"
     },
     "user_tz": -330
    },
    "id": "D1HS3An8vCf2",
    "outputId": "727ab783-9486-4bf3-ff2b-e19ffd0765e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 224, 224 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 64, 224, 224, 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 64, 224, 224, 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                 (None, 64, 224, 224, 448         lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 64, 224, 224, 304         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 64, 224, 224, 784         conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 64, 224, 224, 784         conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D)    (None, 64, 112, 112, 0           conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3D)  (None, 64, 112, 112, 0           conv3d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 64, 112, 112, 2320        max_pooling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 64, 112, 112, 2320        max_pooling3d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 64, 112, 112, 784         conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 64, 112, 112, 784         conv3d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, 64, 56, 56, 1 0           conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3D)  (None, 64, 56, 56, 1 0           conv3d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 64, 56, 56, 3 4640        max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 64, 56, 56, 3 4640        max_pooling3d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 64, 56, 56, 3 3104        conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 64, 56, 56, 3 3104        conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)  (None, 64, 28, 28, 3 0           conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3D)  (None, 64, 28, 28, 3 0           conv3d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 64, 28, 28, 3 9248        max_pooling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 64, 28, 28, 3 9248        max_pooling3d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 64, 28, 28, 3 3104        conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)              (None, 64, 28, 28, 3 3104        conv3d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, 64, 14, 14, 3 0           conv3d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3D)  (None, 64, 14, 14, 3 0           conv3d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 64, 14, 14, 3 0           max_pooling3d_3[0][0]            \n",
      "                                                                 max_pooling3d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3D)  (None, 8, 14, 14, 32 0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_16 (Conv3D)              (None, 8, 14, 14, 64 18496       max_pooling3d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)              (None, 8, 14, 14, 64 12352       conv3d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3D)  (None, 4, 7, 7, 64)  0           conv3d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_18 (Conv3D)              (None, 4, 7, 7, 64)  36928       max_pooling3d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_19 (Conv3D)              (None, 4, 7, 7, 64)  12352       conv3d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling3D) (None, 2, 3, 3, 64)  0           conv3d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_20 (Conv3D)              (None, 2, 3, 3, 128) 73856       max_pooling3d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_21 (Conv3D)              (None, 2, 3, 3, 128) 49280       conv3d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling3D) (None, 1, 1, 1, 128) 0           conv3d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 128)          0           max_pooling3d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          16512       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           4128        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            66          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 272,690\n",
      "Trainable params: 272,690\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(64,224,224,5))\n",
    "\n",
    "rgb = Lambda(get_rgb,output_shape=None)(inputs)\n",
    "opt = Lambda(get_opt,output_shape=None)(inputs)\n",
    "\n",
    "##################################################### RGB channel\n",
    "rgb = Conv3D(\n",
    "    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = Conv3D(\n",
    "    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
    "\n",
    "rgb = Conv3D(\n",
    "    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = Conv3D(\n",
    "    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
    "\n",
    "rgb = Conv3D(\n",
    "    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = Conv3D(\n",
    "    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
    "\n",
    "rgb = Conv3D(\n",
    "    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = Conv3D(\n",
    "    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
    "\n",
    "##################################################### Optical Flow channel\n",
    "opt = Conv3D(\n",
    "    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = Conv3D(\n",
    "    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
    "\n",
    "opt = Conv3D(\n",
    "    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = Conv3D(\n",
    "    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
    "\n",
    "opt = Conv3D(\n",
    "    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = Conv3D(\n",
    "    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
    "\n",
    "opt = Conv3D(\n",
    "    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='sigmoid', padding='same')(opt)\n",
    "opt = Conv3D(\n",
    "    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='sigmoid', padding='same')(opt)\n",
    "opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
    "\n",
    "\n",
    "##################################################### Fusion and Pooling\n",
    "x = Multiply()([rgb,opt])\n",
    "x = MaxPooling3D(pool_size=(8,1,1))(x)\n",
    "\n",
    "##################################################### Merging Block\n",
    "x = Conv3D(\n",
    "    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = Conv3D(\n",
    "    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = MaxPooling3D(pool_size=(2,2,2))(x)\n",
    "\n",
    "x = Conv3D(\n",
    "    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = Conv3D(\n",
    "    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = MaxPooling3D(pool_size=(2,2,2))(x)\n",
    "\n",
    "x = Conv3D(\n",
    "    128, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = Conv3D(\n",
    "    128, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = MaxPooling3D(pool_size=(2,3,3))(x)\n",
    "\n",
    "##################################################### FC Layers\n",
    "x = Flatten()(x)\n",
    "x = Dense(128,activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "# Build the model\n",
    "pred = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=pred)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ft0owI3jvCf4"
   },
   "source": [
    "# Model Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iiOGMpONvCf4"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4UWG3stvCf4"
   },
   "source": [
    "# Set Callbacks\n",
    "\n",
    "    Learning Rate Scheduler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F7Yp71IyvCf5"
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def scheduler(epoch):\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr * 0.7)\n",
    "    return K.get_value(model.optimizer.lr)\n",
    "\n",
    "reduce_lr = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4PMX6hHvCf5"
   },
   "source": [
    "`Saving the best model and training logs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1MHaJyAvCf5"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "import keras\n",
    "\n",
    "class MyCbk(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, model):\n",
    "         self.model_to_save = model\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.model_to_save.save('/content/drive/MyDrive/Project Data/models/model_at_epoch_%d.h5' % (epoch+1))\n",
    "\n",
    "check_point = MyCbk(model)\n",
    "\n",
    "\n",
    "filename = '/content/drive/MyDrive/Project Data/models/ours_log.csv'\n",
    "csv_logger = CSVLogger(filename, separator=',', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ki6vTv0_vCf5"
   },
   "outputs": [],
   "source": [
    "callbacks_list = [check_point, csv_logger, reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NL50g-zfvCf6"
   },
   "source": [
    "# Model Training\n",
    "\n",
    "    set essential params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0wlzP3PFvCf6"
   },
   "outputs": [],
   "source": [
    "num_epochs  = 200\n",
    "num_workers = 16\n",
    "batch_size  = 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pryv00ymvCf6",
    "outputId": "44181ad9-d060-4636-ba62-3302d19b793e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 838 files belonging to 2 classes.\n",
      "  fighting :  0\n",
      "    normal :  1\n",
      "Found 149 files belonging to 2 classes.\n",
      "  fighting :  0\n",
      "    normal :  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_dir = \"/content/drive/MyDrive/Project Data/Fighting Data\"\n",
    "\n",
    "train_generator = DataGenerator(directory=data_dir, split_name = \"training\",\n",
    "                                train_split = 0.85, seed = 12, batch_size=batch_size, \n",
    "                                optical_flow = True, data_augmentation=True)\n",
    "\n",
    "val_generator = DataGenerator(directory=data_dir, split_name = \"validation\",\n",
    "                                train_split = 0.85, seed = 12, batch_size=batch_size, \n",
    "                                optical_flow = True,data_augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSVgSqiQvCf6"
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator=train_generator,validation_data=val_generator,\n",
    "                              callbacks=callbacks_list,verbose=1, epochs=num_epochs,workers=num_workers ,\n",
    "                              max_queue_size=4,steps_per_epoch=len(train_generator),validation_steps=len(val_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZI4b29RvCf7"
   },
   "source": [
    "# plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fYneViSjvCf7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "acc = history.history[\"accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    " \n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    " \n",
    "epoch_range = range(num_epochs)\n",
    " \n",
    "plt.figure(figsize = (16, 8))\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epoch_range, acc, label = \"Training Accuracy\")\n",
    "plt.plot(epoch_range, val_acc, label = \"Validation Accuracy\")\n",
    "plt.legend(loc = \"lower right\")\n",
    " \n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epoch_range, loss, label = \"Training loss\")\n",
    "plt.plot(epoch_range, val_loss, label = \"Validation loss\")\n",
    "plt.legend(loc = \"upper right\")\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UlaJLg_vCf7"
   },
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1ozPDRpvCf8"
   },
   "outputs": [],
   "source": [
    "model.save(\"/content/drive/MyDrive/Project Data/flow_gated_fighting_bs_8.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qkx21ukPvCf8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "3_fighting_with_op_flow_and_transfer_learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
